{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is going to be built on a CPU. Importing csv files for audio below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  gender      PPE      DFA     RPDE  numPulses  numPeriodsPulses  \\\n",
      "0   0       1  0.85247  0.71826  0.57227        240               239   \n",
      "1   0       1  0.76686  0.69481  0.53966        234               233   \n",
      "2   0       1  0.85083  0.67604  0.58982        232               231   \n",
      "3   1       0  0.41121  0.79672  0.59257        178               177   \n",
      "4   1       0  0.32790  0.79782  0.53028        236               235   \n",
      "\n",
      "   meanPeriodPulses  stdDevPeriodPulses  locPctJitter  ...  \\\n",
      "0          0.008064            0.000087       0.00218  ...   \n",
      "1          0.008258            0.000073       0.00195  ...   \n",
      "2          0.008340            0.000060       0.00176  ...   \n",
      "3          0.010858            0.000183       0.00419  ...   \n",
      "4          0.008162            0.002669       0.00535  ...   \n",
      "\n",
      "   tqwt_kurtosisValue_dec_28  tqwt_kurtosisValue_dec_29  \\\n",
      "0                     1.5620                     2.6445   \n",
      "1                     1.5589                     3.6107   \n",
      "2                     1.5643                     2.3308   \n",
      "3                     3.7805                     3.5664   \n",
      "4                     6.1727                     5.8416   \n",
      "\n",
      "   tqwt_kurtosisValue_dec_30  tqwt_kurtosisValue_dec_31  \\\n",
      "0                     3.8686                     4.2105   \n",
      "1                    23.5155                    14.1962   \n",
      "2                     9.4959                    10.7458   \n",
      "3                     5.2558                    14.0403   \n",
      "4                     6.0805                     5.7621   \n",
      "\n",
      "   tqwt_kurtosisValue_dec_32  tqwt_kurtosisValue_dec_33  \\\n",
      "0                     5.1221                     4.4625   \n",
      "1                    11.0261                     9.5082   \n",
      "2                    11.0177                     4.8066   \n",
      "3                     4.2235                     4.6857   \n",
      "4                     7.7817                    11.6891   \n",
      "\n",
      "   tqwt_kurtosisValue_dec_34  tqwt_kurtosisValue_dec_35  \\\n",
      "0                     2.6202                     3.0004   \n",
      "1                     6.5245                     6.3431   \n",
      "2                     2.9199                     3.1495   \n",
      "3                     4.8460                     6.2650   \n",
      "4                     8.2103                     5.0559   \n",
      "\n",
      "   tqwt_kurtosisValue_dec_36  class  \n",
      "0                    18.9405      1  \n",
      "1                    45.1780      1  \n",
      "2                     4.7666      1  \n",
      "3                     4.0603      1  \n",
      "4                     6.1164      1  \n",
      "\n",
      "[5 rows x 755 columns]\n"
     ]
    }
   ],
   "source": [
    "csvData = pd.read_csv('./input/pd_speech_features.csv')\n",
    "print(csvData.head()) #Use to access the data within it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a *rapper class* for the data set using ```torch.utils.data.Dataset``` to load files and formal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(756, 749)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coorelation of a matrix in and pulses. Visualizes it.\n",
    "csvData[[\"numPulses\",\"numPeriodsPulses\"]].corr()\n",
    "#Therefore because 2 attributes are extremely similar to each other, \n",
    "#discard numPeriodsPulses\n",
    "del csvData['numPeriodsPulses']\n",
    "#Make a heatmap of the data to find the best results\n",
    "#sns.heatmap(csvData[csvData.columns[0:10]].corr(),annot=True)\n",
    "del csvData['locPctJitter']  #coor of PCT Jitter and IoC ABS Jitter\n",
    "del csvData['ddpJitter']     #coor ppq5jitter and ddpjitter\n",
    "del csvData['locShimmer']    #coor OCShimmer and IOCDBShimmer\n",
    "del csvData['apq11Shimmer']\n",
    "del csvData['meanNoiseToHarmHarmonicity']\n",
    "csvData.head()\n",
    "\n",
    "#Reduce the number of rows by using automatic selections\n",
    "csvData.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "coor_y = csvData['class']\n",
    "coor_x = csvData.iloc[:,0:747]\n",
    "xnew2=SelectKBest(f_classif, k=20).fit_transform(coor_x, coor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4874</td>\n",
       "      <td>0.028115</td>\n",
       "      <td>0.014642</td>\n",
       "      <td>0.019681</td>\n",
       "      <td>0.012829</td>\n",
       "      <td>0.021703</td>\n",
       "      <td>4.8840</td>\n",
       "      <td>-229943.2967</td>\n",
       "      <td>-201985.0408</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.004324</td>\n",
       "      <td>0.013373</td>\n",
       "      <td>-0.026321</td>\n",
       "      <td>-0.024286</td>\n",
       "      <td>-0.048924</td>\n",
       "      <td>0.022796</td>\n",
       "      <td>0.024286</td>\n",
       "      <td>0.048924</td>\n",
       "      <td>1.5466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.8986</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.019374</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.020296</td>\n",
       "      <td>4.8483</td>\n",
       "      <td>-230526.8175</td>\n",
       "      <td>-203389.4678</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>-0.070039</td>\n",
       "      <td>-0.099695</td>\n",
       "      <td>-0.112210</td>\n",
       "      <td>0.080975</td>\n",
       "      <td>0.099695</td>\n",
       "      <td>0.112210</td>\n",
       "      <td>1.5530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.2208</td>\n",
       "      <td>0.032326</td>\n",
       "      <td>0.024607</td>\n",
       "      <td>0.024819</td>\n",
       "      <td>0.016553</td>\n",
       "      <td>0.023186</td>\n",
       "      <td>1.9849</td>\n",
       "      <td>-246592.6024</td>\n",
       "      <td>-214707.2576</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.008093</td>\n",
       "      <td>-0.019435</td>\n",
       "      <td>-0.026241</td>\n",
       "      <td>-0.039886</td>\n",
       "      <td>0.013810</td>\n",
       "      <td>0.026241</td>\n",
       "      <td>0.039886</td>\n",
       "      <td>1.5399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.1023</td>\n",
       "      <td>0.032577</td>\n",
       "      <td>0.017274</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.015533</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>3.2053</td>\n",
       "      <td>-255107.4287</td>\n",
       "      <td>-160775.5650</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.016104</td>\n",
       "      <td>0.051620</td>\n",
       "      <td>-0.121640</td>\n",
       "      <td>-0.129990</td>\n",
       "      <td>-0.268930</td>\n",
       "      <td>0.111290</td>\n",
       "      <td>0.122970</td>\n",
       "      <td>0.273530</td>\n",
       "      <td>6.9761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.9451</td>\n",
       "      <td>0.031989</td>\n",
       "      <td>0.013791</td>\n",
       "      <td>0.016059</td>\n",
       "      <td>0.014382</td>\n",
       "      <td>0.012686</td>\n",
       "      <td>2.7170</td>\n",
       "      <td>-252647.9964</td>\n",
       "      <td>-154087.6641</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.015422</td>\n",
       "      <td>0.051298</td>\n",
       "      <td>-0.078138</td>\n",
       "      <td>-0.115900</td>\n",
       "      <td>-0.227210</td>\n",
       "      <td>0.086621</td>\n",
       "      <td>0.102950</td>\n",
       "      <td>0.235860</td>\n",
       "      <td>7.8832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5       6  \\\n",
       "0  2.4874  0.028115  0.014642  0.019681  0.012829  0.021703  4.8840   \n",
       "1  2.8986  0.022166  0.025500  0.019374  0.010645  0.020296  4.8483   \n",
       "2  3.2208  0.032326  0.024607  0.024819  0.016553  0.023186  1.9849   \n",
       "3  3.1023  0.032577  0.017274  0.016129  0.015533  0.011976  3.2053   \n",
       "4  2.9451  0.031989  0.013791  0.016059  0.014382  0.012686  2.7170   \n",
       "\n",
       "             7            8         9        10        11        12        13  \\\n",
       "0 -229943.2967 -201985.0408  0.000059  0.005199  0.004324  0.013373 -0.026321   \n",
       "1 -230526.8175 -203389.4678  0.000169  0.005221  0.004344  0.011184 -0.070039   \n",
       "2 -246592.6024 -214707.2576  0.000021  0.003136  0.002657  0.008093 -0.019435   \n",
       "3 -255107.4287 -160775.5650  0.000493  0.004537  0.016104  0.051620 -0.121640   \n",
       "4 -252647.9964 -154087.6641  0.000328  0.003931  0.015422  0.051298 -0.078138   \n",
       "\n",
       "         14        15        16        17        18      19  \n",
       "0 -0.024286 -0.048924  0.022796  0.024286  0.048924  1.5466  \n",
       "1 -0.099695 -0.112210  0.080975  0.099695  0.112210  1.5530  \n",
       "2 -0.026241 -0.039886  0.013810  0.026241  0.039886  1.5399  \n",
       "3 -0.129990 -0.268930  0.111290  0.122970  0.273530  6.9761  \n",
       "4 -0.115900 -0.227210  0.086621  0.102950  0.235860  7.8832  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=pd.DataFrame(xnew2)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, coor_y, test_size=0.25, random_state=43421)\n",
    "rdclass=RandomForestClassifier()\n",
    "rdclass.fit(X_train,y_train)\n",
    "ypred=rdclass.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 21  24]\n",
      " [  9 135]]\n",
      "0.8253968253968254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test,ypred))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set to 44.1kHz frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pd_speech_features.csv']\n",
      "Train set size: 1\n",
      "Test set size: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-195-fb7ad4d01815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0;32m---> 94\u001b[0;31m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "print(os.listdir('/Users/dhritiaravind/Desktop/MLH/Qhacks2020/qhacks/voice_control/input'))\n",
    "\n",
    "class WaveDataset(Dataset):\n",
    "#rapper for the UrbanSound8K dataset\n",
    "    # Argument List\n",
    "    #  path to the UrbanSound8K csv file\n",
    "    #  path to the UrbanSound8K audio files\n",
    "    #  list of folders to use in the dataset\n",
    "    \n",
    "    def __init__(self, csv_path, file_path, folderList):\n",
    "        csvData = pd.read_csv(csv_path)\n",
    "        #initialize lists to hold file names, labels, and folder numbers\n",
    "        self.file_names = []\n",
    "        self.labels = []\n",
    "        self.folders = []\n",
    "        #loop through the csv entries and only add entries from folders in the folder list\n",
    "        for i in range(0,len(csvData)):\n",
    "            if csvData.iloc[i, 5] in folderList:\n",
    "                self.file_names.append(csvData.iloc[i, 0])\n",
    "                self.labels.append(csvData.iloc[i, 6])\n",
    "                self.folders.append(csvData.iloc[i, 5])\n",
    "                \n",
    "        self.file_path = file_path\n",
    "        #self.mixer = torchaudio.transforms.DownmixMono() #UrbanSound8K uses two channels, this will convert them to one\n",
    "        self.folderList = folderList\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        \n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "\n",
    "csv_path = '/Users/dhritiaravind/Desktop/MLH/Qhacks2020/qhacks/voice_control/input/pd_speech_features.csv'\n",
    "file_path = '/Users/dhritiaravind/Desktop/MLH/Qhacks2020/qhacks/voice_control/input/pd_speech_features.csv'\n",
    "\n",
    "train_set = WaveDataset(csv_path, file_path, range(1,10))\n",
    "test_set = WaveDataset(csv_path, file_path, [10])\n",
    "print(\"Train set size: \" + str(len(train_set)))\n",
    "print(\"Test set size: \" + str(len(test_set)))\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device == 'cuda' else {} #needed for using datasets on gpu\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 128, shuffle = True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = 128, shuffle = True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    #Softmax waveform \n",
    "    #Taken from https://arxiv.org/pdf/1610.00087.pdf\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 128, 80, 4)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(128, 128, 3)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(128, 256, 3)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(256, 512, 3)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.avgPool = nn.AvgPool1d(30) #input should be 512x30 so this outputs a 512x1\n",
    "        self.fc1 = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = self.avgPool(x)\n",
    "        x = x.permute(0, 2, 1) #change the 512x1 to 1x512\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim = 2)\n",
    "\n",
    "model = Net()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay = 0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 20, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        data = data.requires_grad_() #set requires_grad to True for training\n",
    "        output = model(data)\n",
    "        output = output.permute(1, 0, 2) #original output dimensions are batchSizex1x10 \n",
    "        loss = F.nll_loss(output[0], target) #the loss functions expects a batchSizex10 input\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0: #print training stats\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        output = output.permute(1, 0, 2)\n",
    "        pred = output.max(2)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target).cpu().sum().item()\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 20\n",
    "for epoch in range(1, 41):\n",
    "    if epoch == 31:\n",
    "        print(\"First round of training complete. Setting learn rate to 0.001.\")\n",
    "    scheduler.step()\n",
    "    train(model, epoch)\n",
    "    test(model, epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
